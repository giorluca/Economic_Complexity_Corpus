Complexity Theory , Game Theory , Economics : Barbados Lectures Barbados Lectures Complexity Theory , Game Theory , Economics Tim Roughgarden 29th McGill Invitational Workshop Computational Complexity Bellairs Institute Holetown , Barbados ar X iv :1 80 1 . 00 73 4v 2 [ c s.C C ] 2 1 ec 20 19 Forward monograph based lecture notes mini-course ‚Äú Complexity Theory , Game Theory , Economics , ‚Äù taught Bellairs Research Institute McGill University , Holetown , Barbados , February 19‚Äì23 , 2017 , 29th McGill Invitational Workshop Computational Complexity . goal mini-course twofold : ( ) explain complexity theory helped illuminate several barriers economics game theory ; ( ii ) illustrate game-theoretic questions led new interesting complexity theory , including several recent breakthroughs . consists two five-lecture sequences : Solar Lectures , focusing communication computa- tional complexity computing equilibria ; Lunar Lectures , focusing applications complexity theory game theory economics.‚àó background game theory assumed . Thanks due many people : Denis Therien Anil Ada organizing workshop inviting lecture ; Omri Weinstein , giving guest lecture simulation theorems communication complexity ; Alex Russell , coordinating scribe notes ; scribes‚Ä† , putting together terrific first draft ; workshop attendees , making experience unforgettable ( intense ! ) . also thank Yakov Babichenko , Mika G√∂√∂s , Aviad Rubinstein , Eylon Yogev , anonymous reviewer numerous helpful comments earlier drafts monograph . writing monograph supported part NSF award CCF-1524062 , Google Faculty Research Award , Guggenheim Fellowship . would happy receive comments corrections readers . Tim Roughgarden Bracciano , Italy December 2017 ( Revised December 2019 ) ‚àóCris Moore : ‚Äú stellar lectures ? ‚Äù ‚Ä†Anil Ada , Amey Bhangale , Shant Boodaghians , Sumegha Garg , Valentine Kabanets , Antonina Kolokolova , Michal Kouck√Ω , Cristopher Moore , Pavel Pudl√°k , Dana Randall , Jacobo Tor√°n , Salil Vadhan , Joshua R. Wang , Omri Weinstein . 2 Contents Forward . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Solar Lectures 7 1 Introduction , Wish List , Two-Player Zero-Sum Games 8 1.1 Nash Equilibria Two-Player Zero-Sum Games . . . . . . . . . . . . . . . . . . . . . . . . 8 1.2 Uncoupled Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 1.3 General Bimatrix Games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 1.4 Approximate Nash Equilibria Bimatrix Games . . . . . . . . . . . . . . . . . . . . . . . 20 2 Communication Complexity Lower Bound Computing Approximate Nash Equilibrium Bimatrix Game ( Part ) 23 2.1 Preamble . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 2.2 Naive Approach : Reduction Disjointness . . . . . . . . . . . . . . . . . . . . . . . . 24 2.3 Finding Brouwer Fixed Points ( -BFP Problem ) . . . . . . . . . . . . . . . . . . . . . 25 2.4 End-of-the-Line ( EoL ) Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 2.5 Road Map Proof Theorem 2.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 2.6 Step 1 : Query Lower Bound EoL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 2.7 Step 2 : Communication Complexity Lower Bound 2EoL via Simulation Theorem . . . 32 3 Communication Complexity Lower Bound Computing Approximate Nash Equilibrium Bimatrix Game ( Part II ) 35 3.1 Step 3 : 2EoL ‚â§ -2BFP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 3.2 Step 4 : -2BFP ‚â§ -NE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 4 TFNP , PPAD , & 45 4.1 Preamble . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 4.2 TFNP Subclasses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46 4.3 PPAD Complete Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 4.4 TFNP Problems Hard ? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 5 Computational Complexity Computing Approximate Nash Equilibrium 55 5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 5.2 Proof Theorem 5.1 : Impressionistic Treatment . . . . . . . . . . . . . . . . . . . . . 56 3 II Lunar Lectures 63 1 Computer Science Influenced Real-World Auction Design . Case Study : 2016‚Äì2017 FCC Incentive Auction 64 1.1 Preamble . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64 1.2 Reverse Auction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64 1.3 Forward Auction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67 2 Communication Barriers Near-Optimal Equilibria 71 2.1 Welfare Maximization Combinatorial Auctions . . . . . . . . . . . . . . . . . . . . . . . 71 2.2 Communication Lower Bounds Approximate Welfare Maximization . . . . . . . . . . . 72 2.3 Lower Bounds Price Anarchy Simple Auctions . . . . . . . . . . . . . . . . . . 75 2.4 Open Question . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79 2.5 Appendix : Proof Theorem 2.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 3 Prices Need Algorithms 81 3.1 Markets Indivisible Items . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81 3.2 Complexity Separations Imply Non-Existence Walrasian Equilibria . . . . . . . . . . . . 84 3.3 Proof Theorem 3.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85 3.4 Beyond Walrasian Equilibria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87 4 Borders Border ‚Äô Theorem 89 4.1 Optimal Single-Item Auctions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89 4.2 Border ‚Äô Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91 4.3 Beyond Single-Item Auctions : Complexity-Theoretic Barrier . . . . . . . . . . . . . . . . 96 4.4 Appendix : Combinatorial Proof Border ‚Äô Theorem . . . . . . . . . . . . . . . . . . . 99 5 Tractable Relaxations Nash Equilibria 101 5.1 Preamble . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101 5.2 Uncoupled Dynamics Revisited . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101 5.3 Correlated Coarse Correlated Equilibria . . . . . . . . . . . . . . . . . . . . . . . . . . 103 5.4 Computing Exact Correlated Coarse Correlated Equilibrium . . . . . . . . . . . . . . 104 5.5 Price Anarchy Coarse Correlated Equilibria . . . . . . . . . . . . . . . . . . . . . 107 Bibliography 109 4 Overview 5 solar lectures 5 lunar lectures . solar lectures focus communication computational complexity computing ( approximate ) Nash equilibrium . lunar lectures less technically intense meant understandable even consuming rum punch ; focus applications computational complexity theory game theory economics . Solar Lectures : Complexity Equilibria Lecture 1 : Introduction wish list . goal first lecture get lay land . ‚Äô focus types positive results equilibria want , like fast algorithms quickly converging distributed processes . positive results possible special cases ( like zero-sum games ) , challenge complexity theory prove extended general case . topics lecture mostly classical . Lectures 2 3 : communication complexity Nash equilibria . two lectures cover themain ideas recent paper Babichenko Rubinstein [ 9 ] , proves strong communication complexity lower bounds computing approximate Nash equilibrium . Discussing proof also gives us excuse talk ‚Äú simulation theorems ‚Äù spirit Raz McKenzie [ 126 ] , lift query complexity lower bounds communication complexity lower bounds recently found number exciting applications . Lecture 4 : TFNP , PPAD , . lecture begin study computational complexity computing Nash equilibrium , want conditional super-polynomial lower bounds . Proving analogs NP-completeness results requires developing customized complexity classes appropriate study equilibrium computation.‚àó lecture also discusses existing evidence intractability complexity classes , including recent developments . Lecture 5 : computational complexity computing approximate Nash equilibrium bima- trix game . goal lecture give high-level overview Rubinstein ‚Äô recent breakthrough result [ 142 ] ETH-type assumption PPAD implies quasi-polynomial-time lower bound problem computing approximate Nash equilibrium ( tight , Corollary 1.17 ) . Lunar Lectures : Complexity-Theoretic Barriers Economics lunar lectures flavor ‚Äú applied complexity theory. ‚Äù ‚Ä† solar lectures build extent , lunar lectures episodic read independently . ‚àóWhy ‚Äô use tried-and-true theory NP-completeness ? guaranteed existence ( Theorem 1.14 ) efficient verifiability Nash equilibrium imply computing one easier task solving NP-complete problems , appropriate complexity assumptions ( see Theorem 4.1 ) . ‚Ä†Not oxymoron ! 5 Lecture 1 : 2016 FCC Incentive Auction . recent FCC Incentive Auction great case study computer science influenced real-world auction design . lecture provides first broader glimpse vibrant field called algorithmic game theory , 10 % concerns complexity computing equilibria . Lecture 2 : Barriers near-optimal equilibria . lecture concerns ‚Äú price anarchy , ‚Äù meaning extent Nash equilibria game approximate optimal outcome . turns nondeterministic communication complexity lower bounds translated , black-box fashion , lower bounds price anarchy . ‚Äô see translation enables theory ‚Äú optimal simple auctions. ‚Äù Lecture 3 : Barriers markets . ‚Äô surely heard idea ‚Äú market-clearing prices , ‚Äù prices market supply equals demand . goods divisible ( milk , wheat , etc . ) , market- clearing prices exist relatively mild technical assumptions . indivisible goods ( houses , spectrum licenses , etc . ) , market-clearing prices may may exist . turns complexity considerations used explain prices exist . cool surprising issue equilibrium existence seems nothing computation ( contrast Solar Lectures , questions studied explicitly computation ) . Lecture 4 : borders Border ‚Äô theorem . Border ‚Äô theorem famous result auction theory 1991 , single-item auctions . Despite fame , one able extend significantly general settings . ‚Äô see complexity theory explains mystery : significantly generalizing Border ‚Äô theorem would imply polynomial hierarchy collapses ! Lecture 5 : Tractable relaxations Nash equilibria . lectures focused largely negative results computing Nash equilibria , epilogue ‚Äô conclude positive algorithmic results relaxations Nash equilibria , correlated equilibria . 6 Part Solar Lectures 7 Solar Lecture 1 Introduction , Wish List , Two-Player Zero-Sum Games 1.1 Nash Equilibria Two-Player Zero-Sum Games 1.1.1 Preamble algorithms person ( like author ) , complexity theory science ‚Äô get want . want ? Let ‚Äô start cool positive results special class games‚Äî two-player zero-sum games‚Äîand study whether extend general games . first positive result , ‚Äô review famous Minimax theorem , see leads polynomial-time algorithm computing Nash equilibrium two-player zero-sum game . ‚Äô show natural ‚Äú dynamics ‚Äù ( basically , distributed algorithm ) converge rapidly approximate Nash equilibrium . 1.1.2 Rock-Paper-Scissors Recall game rock-paper-scissors ( roshambo , like ) 1 : two players , simultaneously picks strategy { rock , paper , scissors } . players choose strategy game draw ; otherwise , rock beats scissors , scissors beats paper , paper beats rock.2 ‚Äô idea : play rock-paper-scissors , go first ? clearly unfair‚Äîno matter strategy choose , response guarantees victory . commit probability distribution three strategies ( called mixed strategy ) ? clear , order operations : ( ) pick distribution ; ( ii ) pick response ; ( iii ) nature flips coins sample strategy distribution . protect yourself‚Äîby picking strategy uniformly random , matter , equal chance win , loss , draw . TheMinimax theorem states , game ‚Äú pure competition ‚Äù like rock-paper-scissors , player always protect suitable randomized strategy‚Äîthere disadvantage move first . proof Minimax theorem also gives byproduct polynomial-time algorithm computing Nash equilibrium ( linear programming ) . 1https : //en.wikipedia.org/wiki/Rock-paper-scissors 2Here fun facts rock-paper-scissors . ‚Äô World Series RPS every year , top prize least $ 50K . watch videos event , see pure psychological warfare . Maybe explains players seem end later rounds tournament every year . ‚Äô also robot hand , built University Tokyo , plays rock-paper-scissors winning probability 100 % ( check video ) . surprise , high-speed camera involved . 8 1.1.3 Formalism specify two-player zero-sum game √ó n payoff matrix numbers . rows correspond possible choices Alice ( ‚Äú row player ‚Äù ) columns correspond possible choices Bob ( ‚Äú column player ‚Äù ) . Entry Ai j contains Alice ‚Äô payoff Alice chooses row Bob chooses column j . zero-sum game , Bob ‚Äô corresponding payoff automatically defined ‚àíAi j . Throughout solar lectures , normalize payoff matrix |Ai j | ‚â§ 1 j.3 example , payoff matrix corresponding rock-paper-scissors : R P R 0 -1 1 P 1 0 -1 -1 1 0 Mixed strategies Alice Bob correspond probability distributions x rows columns , respectively.4 speaking Nash equilibria , one always assumes players randomize independently . two-player zero-sum game mixed strategies x , , write Alice ‚Äô expected payoff x > Ay = ‚àë , j Ai j xiyj . Bob ‚Äô expected payoff negative quantity , goal minimize expression . 1.1.4 Minimax Theorem question Minimax theorem addresses following : two players make choices sequentially zero-sum game , better go first second ? zero-sum game , first-mover disadvantage . Going second gives player opportunity adapt player first . second player always option choosing whatever mixed strategy would chosen gone first . going second ever strictly help ? Minimax theorem gives amazing answer question : ‚Äô matter ! Theorem 1.1 ( Minimax Theorem ) . Let payoff matrix two-player zero-sum game . max x ( min x > Ay ) = min ( max x x > Ay ) , ( 1.1 ) x range probability distributions rows columns , respectively . left-hand side ( 1.1 ) , row player moves first column player second . column player plays optimally given strategy chosen row player , row player plays optimally anticipating column player ‚Äô response . right-hand side ( 1.1 ) , roles two players reversed . Minimax theorem asserts , optimal play , expected payoff player scenarios . 3This without loss generality , scaling . 4A pure strategy special case mixed strategy deterministic ( i.e. , allots probability single strategy ) . 9 first proof Minimax theorem due von Neumann [ 156 ] used fixed-point-type arguments ( ‚Äô much say later ) . von Neumann Morgenstern [ 157 ] , inspired Ville [ 155 ] , later realized Minimax theorem deduced strong linear programming duality.5 Proof . idea formulate problem faced first player linear program . theorem follow linear programming duality . First , player moves second always optimal pure ( i.e. , deterministic ) strategy‚Äîgiven probability distribution chosen first player , second player simply play strategy highest expected payoff . means inner min max ( 1.1 ) may well range columns rows , respectively , rather probability distributions . expression left-hand side ( 1.1 ) translates following linear program : max x , v v s.t . v ‚â§ m‚àë i=1 Ai j xi columns j , x probability distribution rows . optimal point ( v‚àó , x‚àó ) , v‚àó equals left-hand-side ( 1.1 ) x‚àó belongs corresponding arg-max . plain terms , x‚àó Alice play move first , v‚àó consequent expected payoff ( assuming Bob responds optimally ) . Similarly , write second linear program computes optimal point ( w‚àó , y‚àó ) Bob ‚Äô perspective , w‚àó equals right-hand-side ( 1.1 ) y‚àó corresponding arg-min : min , w w s.t . w ‚â• n‚àë j=1 Ai j yj rows , probability distribution columns . straightforward verify two linear programs fact duals ( left reader , see Chv√°tal [ 39 ] ) . strong linear programming duality , know two linear programs equal optimal objective function value hence v‚àó = w‚àó . means payoff Alice guarantee goes first Bob goes first ( plays optimally ) , completing proof .  5Dantzig [ 42 , p.5 ] describes meeting John von Neumann October 3 , 1947 : ‚Äú minute slapped geometric algebraic version [ linear programming ] problem blackboard . Von Neumann stood said ‚Äò Oh ! ‚Äô next hour half , proceeded give lecture mathematical theory linear programs . ‚Äú one point seeing sitting eyes popping mouth open ( searched literature found nothing ) , von Neumann said : ‚Äò ‚Äô want think pulling sleeve spur moment like magician . recently completed book Oskar Morgenstern Theory Games . conjecturing two problems equivalent. ‚Äù equivalence strong linear programming duality Minimax theorem made precise Dantzig [ 41 ] , Gale et al . [ 60 ] , Adler [ 2 ] . 10 Definition 1.2 ( Values Min-Max Pairs ) . Let payoff matrix two-player zero-sum game . value game defined common value max x ( min x > Ay ) min ( max x x > Ay ) . min-max strategy strategy x‚àó arg-max left-hand side strategy y‚àó arg-min right-hand side . min-max pair pair ( x‚àó , y‚àó ) x‚àó y‚àó min-max strategies . example , value rock-paper-scissors game 0 ( u , u ) unique min-max pair , u denotes uniform probability distribution . min-max pairs optimal solutions two linear programs proof Theorem 1.1 . optimal solution linear program computed polynomial time , min-max pair . 1.1.5 Nash Equilibrium zero-sum games , min-max pair closely related notion Nash equilibrium , defined next.6 Definition 1.3 ( Nash Equilibrium Two-Player Zero-Sum Game ) . Let payoff matrix two-player zero-sum game . pair ( xÀÜ , yÀÜ ) Nash equilibrium : ( ) xÀÜ > AyÀÜ ‚â• x > AyÀÜ x ( given Bob plays yÀÜ , Alice increase expected payoff deviating unilaterally strategy different xÀÜ , i.e. , xÀÜ optimal given yÀÜ ) ; ( ii ) xÀÜ > AyÀÜ ‚â§ xÀÜ > Ay ( given xÀÜ , yÀÜ optimal strategy Bob ) . pairs Definition 1.3 sometimes called mixed Nash equilibria , stress players allowed randomize . ( opposed pure Nash equilibrium , players play deterministically . ) Unless otherwise noted , always concerned mixed Nash equilibria . Proposition 1.4 ( Equivalence Nash Equilibria Min-Max Pairs ) . two-player zero-sum game , pair ( x‚àó , y‚àó ) min-max pair Nash equilibrium . Proof . Suppose ( x‚àó , y‚àó ) min-max pair , Alice ‚Äô expected payoff v‚àó , value game . Alice plays min-max strategy , Bob make payoff smaller v‚àó via strategy . Bob plays min-max strategy , Alice make payoff larger v‚àó . Neither player better unilateral deviation , ( x‚àó , y‚àó ) Nash equilibrium . Conversely , suppose ( x‚àó , y‚àó ) min-max pair , say , Alice playing min-max strategy . Alice ‚Äô expected payoff less v‚àó , ( x‚àó , y‚àó ) Nash equilibrium ( could better deviating min-max strategy ) . Otherwise , x‚àó min-max strategy , Bob response Alice ‚Äô expected payoff would strictly less v‚àó . , Bob could better deviating unilaterally . case , ( x‚àó , y‚àó ) Nash equilibrium .  several interesting consequences Theorem 1.1 Proposition 1.4 : 1 . set Nash equilibria two-player zero-sum game convex , optimal solutions linear program form convex set . 6If think learned definition movie Beautiful Mind , ‚Äô time learn correct definition ! 11 2 . Nash equilibria ( x , ) two-player zero-sum game lead value x > Ay . , player receives expected payoff across Nash equilibria . 3 . importantly , proof Theorem 1.1 provides polynomial-time algorithm compute min-max pair ( x‚àó , y‚àó ) , polynomial-time algorithm compute Nash equilibrium two-player zero-sum game . Corollary 1.5 . Nash equilibrium two-player zero-sum game computed polynomial time . 1.1.6 Beyond Zero-Sum Games ( Computational Complexity ) generalize Corollary 1.5 general classes games ? , two-player zero-sum games important‚Äîvon Neumann largely focused , applications ranging poker war‚Äîmost game-theoretic situations purely zero-sum.7 example , bimatrix games , still two players game necessarily zero-sum ? 8 Solar Lectures 4 5 devoted question , provide evidence polynomial-time algorithm computing Nash equilibrium ( even approximate one ) bimatrix game . 1.1.7 Cares ? proceeding second cool fact two-player zero-sum games , let ‚Äô take step back clear ‚Äô trying accomplish . care computing equilibria games , anyway ? 1 . might want fast algorithms use practice . demand equilibrium computation algorithms significantly less , say , linear programming solvers , author regularly meets researchers would make good use better off-the-shelf solvers computing equilibrium game . 2 . Perhaps relevant monograph ‚Äô audience , study equilibrium computation naturally leads interesting new complexity theory ( e.g. , definitions new complexity classes , PPAD ) . see celebrated results area quite deep draw ideas across theoretical computer science . 3 . Complexity considerations used support critique practical relevance equilibrium concept Nash equilibrium . tempting interpret polynomial-time algorithm computing equilibrium plausibility argument players figure one quickly , intractability result evidence players generally reach equilibrium reasonable amount time . course , real story complex . First , computational intractability necessarily first list Nash equilibrium ‚Äô issues . example , non-uniqueness non-zero-sum games already limits predictive power.9 7Games even collaborative aspect , example want meet intersection Manhattan . strategies intersections , either get high payoff ( choose strategy ) get low payoff ( otherwise ) . 8Notice three-player zero-sum games already general bimatrix games‚Äîto turn one latter one former , add dummy third player one strategy whose payoff negative combined payoff original two players . Thus compelling negative results would case bimatrix games . 9Recall ‚Äú meeting Manhattan ‚Äù example‚Äîevery intersection Nash equilibrium ! 12 Second , ‚Äô particularly helpful critique definition without suggesting alternative . Lunar Lecture 5 partially addresses issue discussing two tractable equilibrium concepts , correlated equilibria coarse correlated equilibria . Third , arbitrary polynomial-time algorithm , one based solving non-trivial linear program , really suggest independent play strategic players actually converge equilibrium ? Algorithms linear programming resemble players typically make decisions games . stronger positive result would involve behaviorally plausible distributed algorithm players use efficiently converge Nash equilibrium repeated play time . discuss result two-player zero-sum games next . 1.2 Uncoupled Dynamics first half lecture , saw Nash equilibrium two-player zero-sum game computed polynomial time using linear programming . would compelling , however , come definition plausible process players learn Nash equilibrium . result requires behavioral model players equilibrium . goal investigate whether process converges Nash equilibrium ( appropriate notion convergence ) , , quickly . 1.2.1 Setup Uncoupled dynamics refers class processes properties mentioned . idea player initially knows payoffs ( players ) , √† la number-in-hand model communication complexity.10 game played repeatedly , player picking strategy time step function payoffs transpired past . Uncoupled Dynamics ( Two-Player Version ) time step = 1 , 2 , 3 , . . . : 1 . Alice chooses strategy xt function payoffs previously chosen strategies x1 , . . . , xt‚àí1 y1 , . . . , yt‚àí1 . 2 . Bob simultaneously chooses strategy yt function payoffs previously chosen strategies x1 , . . . , xt‚àí1 y1 , . . . , yt‚àí1 . 3 . Alice learns yt Bob learns xt .11 Uncoupled dynamics studied length game theory computer science literatures ( often different names ) . Specifying dynamics boils definition Alice Bob 10If player knows game zero-sum also payoff matrix , automatically knows player ‚Äô payoff matrix . Nonetheless , non-trivial illuminating investigate convergence properties general-purpose uncoupled dynamics zero-sum case , thereby identifying aspiration point analysis general games . 11When Alice Bob use mixed strategies , two natural feedback models , one player learns actual mixed strategy chosen player , one learns sample ( pure strategy ) player ‚Äô chosen distribution . ‚Äô generally easier prove results first model , proofs usually extended additional work hold ( high probability strategy realizations ) second model well . 13 choose strategies function payoffs joint history play . Let ‚Äô look famous examples . 1.2.2 Fictitious Play One natural idea best respond observed behavior opponent . Example 1.6 ( Fictitious Play ) . fictitious play , player assumes player mix according relative frequencies past actions ( i.e. , empirical distribution past play ) , plays best response.12 Fictitious Play ( Two-Player Version ) time step = 1 , 2 , 3 , . . . : 1 . Alice chooses strategy xt best response yÀÜt‚àí1 = 1t‚àí1 ‚àët‚àí1 s=1 , past actions Bob ( breaking ties arbitrarily ) . 2 . Bob simultaneously chooses strategy yt best response xÀÜt‚àí1 = 1t‚àí1 ‚àët‚àí1 s=1 x , past actions Alice ( breaking ties arbitrarily ) . 3 . Alice learns yt Bob learns xt . Note player picks pure strategy time step ( modulo tie-breaking case multiple best responses ) . One way interpret fictitious play imagine player assumes using mixed strategy every time step , estimates time-invariant mixed strategy empirical distribution strategies chosen past . Fictitious play interesting history : 1 . first proposed G. W. Brown 1949 ( published 1951 [ 20 ] ) computer algorithm compute Nash equilibrium two-player zero-sum game . long birth either game theory computers ! 2 . 1951 , Julia Robinson ( better known contributions resolution Hilbert ‚Äô tenth problem Diophantine equations ) proved , two-player zero-sum games , time-averaged payoffs players converge value game [ 129 ] . Robinson ‚Äô proof gives exponential ( number strategies ) bound number iterations required convergence . 1959 , Karlin [ 89 ] conjectured polynomial bound possible ( two-player zero-sum games ) . Fast forward 2014 , Daskalakis Pan [ 43 ] refuted Karlin ‚Äô conjecture proved exponential lower bound case adversarial ( necessarily consistent ) tie-breaking . 3 . still open question whether fictitious play converges quickly two-player zero-sum games natural ( even consistent ) tie-breaking rules ! goal would show poly ( n , 1/ ) time steps suffice time-averaged payoffs within  value game ( n total number rows columns ) . 12In first time step , Alice Bob choose default strategy , uniform distribution . 14 4 . situation non-zero-sum games murky 1964 , Lloyd Shapley discovered 3 √ó 3 game ( non-zero-sum variation rock-paper-scissors ) fictitious play never converges Nash equilibrium [ 145 ] . Shapley ‚Äô counterexample foreshadowed future separations tractability zero-sum non-zero-sum games . Next ‚Äô look different choice dynamics better convergence properties . 1.2.3 Smooth Fictitious Play Fictitious play ‚Äú all-or-nothing ‚Äù ‚Äîeven two strategies almost expected payoff opponent ‚Äô empirical distribution , slightly worse one completely ignored favor slightly better one . stable approach , perhaps behaviorally plausible one , assume players randomize , biasing decision toward strategies highest expected payoffs ( , empirical distribution opponent ) . words , player plays ‚Äú noisy best response ‚Äù observed play player . example , already 1957 Hannan [ 75 ] considered dynamics player chooses strategy probability proportional expected payoff ( empirical distribution player ‚Äô past play ) , proved polynomial convergence Nash equilibrium payoffs two-player zero-sum games . Even better convergence properties possible poorly performing strategies abandoned aggressively , corresponding ‚Äú softmax ‚Äù version fictitious play . Example 1.7 ( Smooth Fictitious Play ) . time smooth fictitious play , player ( Alice , say ) computes empirical distribution yÀÜt‚àí1 = ‚àët‚àí1 s=1 player ‚Äô past play , computes expected payoff piti pure strategy assumption Bob plays yÀÜt‚àí1 , chooses xt playing strategy probability proportional eŒ∑tpi ti . ( = 1 , interpret piti ‚Äô 0 hence player chooses uniform distribution . ) Œ∑t tunable parameter interpolates always playing uniformly random ( Œ∑ = 0 ) fictitious play random tie-breaking ( Œ∑ = +‚àû ) . choice Œ∑t ‚âà ‚àöt often best one proving convergence results . Smooth Fictitious Play ( Two-Player Version ) Given : parameter family { Œ∑t ‚àà [ 0 , ‚àû ) : = 1 , 2 , 3 , . . . } . time step = 1 , 2 , 3 , . . . : 1 . Alice chooses strategy xt playing strategy probability proportional eŒ∑tpi ti , piti denotes expected payoff strategy Bob plays mixed strategy yÀÜ t‚àí1 = 1 t‚àí1 ‚àët‚àí1 s=1 s. 2 . Bob simultaneously chooses strategy yt playing strategy j probability proportional eŒ∑ tpi tj , pitj expected payoff strategy j Alice plays mixed strategy xÀÜt‚àí1 = 1t‚àí1 ‚àët‚àí1 s=1 x s. 3 . Alice learns yt Bob learns xt . Versions smooth fictitious play studied independently game theory literature ( beginning Fudenberg Levine [ 59 ] ) computer science literature ( beginning Freund Schapire [ 58 ] ) . converges extremely quickly . 15 Theorem 1.8 ( Fast Convergence Smooth Fictitious Play [ 59 , 58 ] ) . zero-sum two-player game rows n columns parameter  > 0 , = ( log ( n + ) /2 ) time steps smooth fictitious play Œ∑t = Œò ( ‚àöt ) , empirical distributions xÀÜ = 1T ‚àëT t=1 x yÀÜ = 1T ‚àëT t=1 constitute -approximate Nash equilibrium . -approximate Nash equilibrium condition Theorem 1.8 exactly sounds like : neither player improve expected payoff  via unilateral deviation ( see also Definition 1.12 , ) .13 two steps proof Theorem 1.8 : ( ) noisy best response smooth fictitious play equivalent ‚Äú Exponential Weights ‚Äù algorithm , ‚Äú vanishing regret ‚Äù ; ( ii ) two-player zero-sum game , vanishing-regret guarantees translate ( approximate ) Nash equilibrium convergence . optional Sections 1.2.5‚Äì1.2.7 provide details interested reader . 1.2.4 Beyond Zero-Sum Games ( Communication Complexity ) Theorem 1.8 implies smooth fictitious play used define randomized ( log2 ( n + ) /2 ) - bit communication protocol computing -NE two-player zero sum game.14 goal Solar Lectures 2 3 prove analogously efficient communication protocol computing approximate Nash equilibrium general bimatrix game.15 Ruling low-communication protocols particular rule type quickly converging uncoupled dynamics.16 1.2.5 Proof Theorem 1.8 , Part 1 : Exponential Weights ( Optional ) elaborate first step proof Theorem 1.8 , need explain standard setup online decision-making . Online Decision-Making time step = 1 , 2 , . . . , : decision-maker picks probability distribution pt actions Œõ adversary picks reward vector r : Œõ‚Üí [ ‚àí1 , 1 ] action chosen according distribution pt , decision-maker receives reward r ( ) decision-maker learns r , entire reward vector smooth fictitious play , Alice Bob effect solving online decision-making problem ( actions corresponding game ‚Äô strategies ) . Alice , reward vector r induced Bob ‚Äô 13Recall assumption payoffs scaled lie [ ‚àí1 , 1 ] . 14This communication bound applies variant smooth fictitious play Alice ( respectively , Bob ) learns random sample yt ( respectively , xt ) ; see footnote 11 . sample communicated player log ( n + ) bits . Theorem 1.8 continues hold ( high probability samples ) variant smooth fictitious play [ 59 , 58 ] . 15The communication complexity computing anything two-player zero-sum game zero‚ÄîAlice knows entire game beginning ( Bob ‚Äô payoff negative ) unilaterally compute whatever wants . still makes sense ask communication bound implied smooth fictitious play replicated non-zero-games ( Alice Bob initially know payoff matrices ) . 16The relevance communication complexity fast learning games first pointed Conitzer Sandholm [ 40 ] . 16 action time step ( Bob plays strategy j , r jth column game matrix ) , similarly Bob ( reward vector equal ith row multiplied ‚àí1 ) . Next interpret Alice ‚Äô Bob ‚Äô behavior smooth fictitious play algorithms online decision-making . online decision-making algorithm specifies probability distribution pt , function reward vectors r1 , . . . , r t‚àí1 realized actions a1 , . . . , at‚àí1 first ‚àí 1 time steps . adversary algorithm specifies reward vector r , function probability distributions p1 , . . . , pt used first days realized actions a1 , . . . , at‚àí1 first ‚àí 1 days . famous online decision-making algorithm , ‚Äú ExponentialWeights ( EW ) ‚Äù algorithm ( see [ 105 , 57 ] ) .17 Exponential Weights ( EW ) Algorithm initialize w1 ( ) = 1 every ‚àà Œõ time step = 1 , 2 , 3 , . . . use distribution pt : = wt/Œìt actions , Œìt = ‚àëa‚ààŒõ wt ( ) sum actions ‚Äô current weights given reward vector r , update weight action ‚àà Œõ using formula wt+1 ( ) = wt ( ) ¬∑ ( eŒ∑tr ( ) ) ( Œ∑t parameter , canonically ‚âà ‚àöt ) EW algorithm maintains weight , intuitively ‚Äú credibility , ‚Äù action . time step algorithm chooses action probability proportional current weight . weight action evolves time according action ‚Äô past performance . Inspecting descriptions smooth fictitious play EW algorithm , see rephrase former follows : Smooth Fictitious Play ( Rephrased ) Given : parameter family { Œ∑t ‚àà [ 0 , ‚àû ) : = 1 , 2 , 3 , . . . } . time step = 1 , 2 , 3 , . . . : 1 . Alice uses instantiation EW algorithm choose mixed strategy xt . 2 . Bob uses different instantiation EW algorithm choose mixed strategy yt . 3 . Alice learns yt Bob learns xt . 4 . Alice feeds EW algorithm reward vector r r ( ) equal expected payoff playing row , given Bob ‚Äô mixed strategy yt columns ; similarly Bob . assess performance online decision-making algorithm like EW algorithm , guarantees algorithm implications smooth fictitious play ? 17Also known ‚Äú Hedge ‚Äù algorithm . closely related ‚Äú Multiplicative Weights ‚Äù algorithm uses update rule wt+1 ( ) = wt ( ) ¬∑ ( 1 + Œ∑tr ( ) ) instead wt+1 ( ) = wt ( ) ¬∑ ( eŒ∑t r ( ) ) [ 27 ] . 17 1.2.6 Proof Theorem 1.8 , Part 2 : Vanishing Regret ( Optional ) One big ideas online learning compare time-averaged reward earned online algorithm earned best fixed action hindsight.18 Definition 1.9 ( ( Time-Averaged ) Regret ) . Fix reward vectors r1 , . . . , rT . regret action sequence a1 , . . . , 1 max a‚ààŒõ T‚àë t=1 r ( ) Ô∏∏ Ô∏∑Ô∏∑ Ô∏∏ best fixed action ‚àí 1 T‚àë t=1 r ( ) Ô∏∏ Ô∏∑Ô∏∑ Ô∏∏ algorithm . ( 1.2 ) Note , linearity , difference considering best fixed action best fixed distribution actions ( always optimal pure action hindsight ) . aspire online decision-making algorithm achieves low regret , close 0 possible . rewards lie [ ‚àí1 , 1 ] , regret never larger 2 . think regret ‚Ñ¶ ( 1 ) ( ‚Üí‚àû ) epic fail algorithm . turns EW algorithm best-possible worst-case regret guarantee ( constant factors ) .19 Theorem 1.10 ( Regret Bound EW Algorithm ) . every adversary , EW algorithm expected regret ( ‚àö ( log n ) /T ) , n = |Œõ| . See e.g . book Cesa-Bianchi Lugosi [ 26 ] proof Theorem 1.10 , overly difficult . immediate corollary number time steps needed drive expected regret small constant logarithmic number actions‚Äîthis surprisingly fast ! Corollary 1.11 . online decision-making algorithm , every adversary  > 0 , expected regret  ( ( log n ) /2 ) time steps , n = |Œõ| . 1.2.7 Proof Theorem 1.8 , Part 3 : Vanishing Regret Implies Convergence ( Optional ) Consider zero-sum game payoffs [ ‚àí1 , 1 ]  > 0 . Let n denote number rows number columns , whichever larger , set = Œò ( ( log n ) /2 ) guarantee Corollary 1.11 holds error /2 . Let x1 , . . . , xT y1 , . . . , yT mixed strategies used Alice Bob throughout steps smooth fictitious play . Let xÀÜ = 1T ‚àëT t=1 x yÀÜ = 1T ‚àëT t=1 denote time-averaged strategies Alice Bob , respectively . claim ( xÀÜ , yÀÜ ) -NE . proof , let v = 1 T‚àë t=1 ( xt ) > Ayt 18There hope competing best action sequence hindsight : consider two actions adversary flips coin time step choose reward vectors ( 1 , 0 ) ( 0 , 1 ) . 19For matching lower bound , n actions , consider adversary sets reward action uniformly random { ‚àí1 , 1 } time step . Every online algorithm earns expected cumulative reward 0 , expected cumulative reward best action hindsight Œò ( ‚àöT ¬∑ ‚àölog n ) . 18 denote Alice ‚Äô time-averaged payoff . Alice Bob used ( effect ) EW algorithm choose strategies , apply vanishing regret guarantee Corollary 1.11 player use linearity obtain v ‚â• ( max x 1 T‚àë t=1 x > Ayt ) ‚àí  2 = ( max x x > AyÀÜ ) ‚àí  2 ( 1.3 ) v ‚â§ ( min 1 T‚àë t=1 ( xt ) > Ay ) +  2 = ( min xÀÜ > Ay ) +  2 . ( 1.4 ) particular , taking x = xÀÜ ( 1.3 ) = yÀÜ ( 1.4 ) shows xÀÜ > AyÀÜ ‚àà [ v ‚àí  2 , v +  2 ] . ( 1.5 ) consider ( pure ) deviation ( xÀÜ , yÀÜ ) , say Alice row i. Denote deviation ei . inequality ( 1.3 ) ( x = ei ) e > AyÀÜ ‚â§ v +  2 . ( 1.6 ) Alice receives expected payoff least v ‚àí 2 ( xÀÜ , yÀÜ ) ( ( 1.5 ) ) v + 2 deviation ( ( 1.6 ) ) , -NE conditions satisfied . symmetric argument applies Bob , completing proof . 1.3 General Bimatrix Games general bimatrix game defined two independent payoff matrices , √ó n matrix Alice m√ónmatrix B Bob . ( zero-sum game , B = ‚àíA . ) definition ( approximate ) Nash equilibrium ‚Äô think would : Definition 1.12 ( -Approximate Nash Equilibrium ) . bimatrix game ( , B ) , row column mixed strategies xÀÜ yÀÜ constitute -NE xÀÜ > AyÀÜ ‚â• x > AyÀÜ ‚àí  ‚àÄx , ( 1.7 ) xÀÜ > B yÀÜ ‚â• xÀÜ > ‚àí  ‚àÄy . ( 1.8 ) long known many nice properties zero-sum games break general bimatrix games.20 Example 1.13 ( Strange Bimatrix Behavior ) . Suppose two friends , Alice Bob , want go dinner , trying agree restaurant . Alice prefers Italian Thai , Bob prefers Thai Italian , would rather eat together eat alone.21 Supposing rows columns indexed Italian Thai , order , Alice row player , get following payoff matrices : = [ 2 0 0 1 ] , B = [ 1 0 0 2 ] , , shorthand , ( , B ) = [ ( 2 , 1 ) ( 0 , 0 ) ( 0 , 0 ) ( 1 , 2 ) ] . two obvious Nash equilibria , pure : either Alice Bob go Italian restaurant , go Thai restaurant . ‚Äô third Nash equilibrium , mixed one22 : Alice chooses Italian 20We already mentioned Shapley ‚Äô 1964 example showing fictitious play need converge [ 145 ] . 21In older game theory texts , example called ‚Äú Battle Sexes. ‚Äù 22Fun fact : outside degenerate cases , every game odd number Nash equilibria ( see also Solar Lecture 4 ) . 19 Thai probability 23 , Bob chooses Thai Italian probability 2 3 . undesirable Nash equilibrium , Alice Bob eating alone half time . Example 1.13 shows , unlike zero-sum games , different Nash equilibria result different expected player payoffs . Similarly , Nash equilibria bimatrix game generally form convex set ( unlike zero-sum case ) . Nash equilibria bimatrix games completely devoid nice properties , however . starters , guaranteed existence . Theorem 1.14 ( Nash ‚Äô Theorem [ 119 , 118 ] ) . Every bimatrix game least one ( mixed ) Nash equilibrium . proof fixed-point argument say Solar Lecture 2.23 Nash ‚Äô theorem holds generally games finite number players strategies . Nash equilibria bimatrix games nicer structure games three players . First , bimatrix games integer payoffs , Nash equilibrium probabilities rational numbers bit complexity polynomial game.24 Second , simplex-type pivoting algorithm , called Lemke-Howson algorithm [ 101 ] , computes Nash equilibrium bimatrix game finite number steps ( see von Stengel [ 158 ] survey ) . Like simplex method , Lemke-Howson algorithm takes exponential number steps worst case [ 114 , 143 ] . similarities Nash equilibria bimatrix games optimal solutions linear programs initially led optimism computing former might easy computing latter ( i.e. , might polynomial-time solvable problem ) . Alas , ‚Äô see , seem case . 1.4 Approximate Nash Equilibria Bimatrix Games last topic lecture semi-positive results approximate Nash equilibria general bimatrix games . simple , results important show repeatedly rest lectures . 1.4.1 Sparse Approximate Nash Equilibria crucial result us : always sparse approximate Nash equilibria.25,26 Theorem 1.15 ( Existence Sparse Approximate Nash Equilibria ( Lipton et al . [ 104 ] ) ) . every  > 0 every n √ó n bimatrix game , exists -NE player randomizes uniformly multi-set ( ( log n ) /2 ) pure strategies.27 Proof idea . Fix n √ó n bimatrix game ( , B ) . 1 . Let ( x‚àó , y‚àó ) exact Nash equilibrium ( , B ) . ( One exists , Theorem 1.14 . ) 23Von Neumann ‚Äô alleged reaction Nash told theorem [ 117 , P.94 ] : ‚Äú ‚Äô trivial , know . ‚Äô fixed point theorem. ‚Äù 24Exercise : prove showing , ‚Äô guessed two support sets Nash equilibrium , recover exact probabilities using two linear programs . 25Alth√∂fer [ 4 ] Lipton Young [ 103 ] independently proved precursor result special case zero-sum games . focus latter paper applications complexity theory ( like ‚Äú anticheckers ‚Äù ) . 26Exercise : arbitrarily large games every exact Nash equilibrium full support . Hint : generalize rock-paper- scissors . Alternatively , see Section 5.2.6 Solar Lecture 5 . 27By padding argument , loss generality assuming Alice Bob number strategies . 20 2 . thought experiment , sample Œò ( ( log n ) /2 ) pure strategies Alice i.i.d . ( replacement ) x‚àó , similarly Bob i.i.d . y‚àó . 3 . Let xÀÜ , yÀÜ denote empirical distributions samples ( probabilities equal frequencies sample ) ‚Äîequivalently , uniform distributions two multi-sets pure strategies . 4 . Use Chernoff bounds argue ( xÀÜ , yÀÜ ) -NE ( high probability ) . Specifically , choice number samples , expected payoff row strategy w.r.t . yÀÜ differs w.r.t . y‚àó /2 ( w.h.p. ) . every strategy played non-zero probability x‚àó exact best response y‚àó , every strategy played non-zero probability xÀÜ within  best response yÀÜ . ( argument applies roles xÀÜ yÀÜ reversed . ) sufficient condition -NE.28  1.4.2 Implications Communication Complexity Theorem 1.15 immediately implies existence -NE n√ón bimatrix gamewith description length ( ( log2 n ) /2 ) , ‚âà log n bits used describe ( ( log n ) /2 ) pure strategies multi-sets promised theorem . Moreover , all-powerful prover writes alleged description publicly observable blackboard , Alice Bob privately verify described pair mixed strategies indeed -NE . example , Alice use ( publicly viewable ) description Bob ‚Äô mixed strategy compute expected payoff best response check  expected payoff playing mixed strategy suggested prover . Summarizing : Corollary 1.16 ( PolylogarithmicNondeterministicCommunicationComplexity ) . nondeterministic com- munication complexity computing -NE n √ó n bimatrix game ( ( log2 n ) /2 ) . Thus , polynomial lower bound deterministic randomized communication complexity computing approximate Nash equilibrium , way prove via techniques ‚Äô automatically apply also problem ‚Äô nondeterministic communication complexity . observation rules many common lower bound techniques . Solar Lectures 2 3 , ‚Äô see thread needle using simulation theorem , lifts deterministic random query ( i.e. , decision tree ) lower bound analogous communication complexity lower bound . 1.4.3 Implications Computational Complexity second important consequence Theorem 1.15 limit worst-possible computational hardness could hope prove problem computing approximate Nash equilibrium bimatrix game : worst , problem quasi-polynomial-hard . Corollary 1.17 ( Quasi-Polynomial Computational Complexity ) . algorithm , given input description n √ó n bimatrix game parameter  , outputs -NE ( ( log n ) /2 ) time . Proof . algorithm enumerates ( ( log n ) /2 ) possible choices multi-sets promised Theo- rem 1.15 . easy check whether mixed strategies induced choice constitute -NE‚Äîjust compute expected payoffs strategy players ‚Äô best responses , proof Corollary 1.16 .  28This sufficient condition name : well-supported -NE . 21 apparent paucity natural problems quasi-polynomial complexity , quasi- polynomial-time approximation scheme ( QPTAS ) Corollary 1.17 initially led optimism PTAS problem . Also , reduction showing quasi-polynomial-time hardness computing approximate Nash equilibrium , would appropriate complexity assumption , would reduction look like ? Solar Lectures 4 5 answer question . 22 Solar Lecture 2 Communication Complexity Lower Bound Computing Approximate Nash Equilibrium Bimatrix Game ( Part ) lecture next consider communication complexity computing approximate Nash equilibrium , culminating proof recent breakthrough polynomial lower bound Babichenko Rubinstein [ 9 ] . lower bound rules possibility quickly converging uncoupled dynamics general bimatrix games ( see Section 1.2 ) . 2.1 Preamble Recall setup : two players , Alice Bob , payoff matrices B . Without loss generality ( padding ) , two players number N strategies . consider two-party model , initially , Alice knows Bob knows B . goal Alice Bob compute approximate Nash equilibrium ( Definition 1.12 ) little communication possible . lecture next explain main ideas behind following result : Theorem 2.1 ( Babichenko Rubinstein [ 9 ] ) . constant c > 0 , sufficiently small constants  > 0 sufficiently large N , randomized communication complexity computing -NE ‚Ñ¶ ( Nc ) .1 purposes , randomized protocol communication cost b always uses b bits communication , terminates least one player knowing -NE game probability least 12 ( protocol ‚Äô coin flips ) . Thus , lots obstacles players reaching equilibriumof game ( see also Section 1.1.7 ) , communication alone already significant bottleneck . corollary Theorem 2.1 uncoupled dynamics ( Section 1.2 ) converge approximate Nash equilibrium sub-polynomial number rounds general bimatrix games ( cf. , guarantee Theorem 1.8 smooth fictitious play zero-sum games ) . uncoupled dynamics simulated randomized communication protocol logarithmic overhead ( communicate strategy gets played round ) .2 corollary regarded fundamental contribution pure game theory economics . goal next lecture sketch full proof lower bound Theorem 2.1 deterministic communication protocols . really care randomized protocols , however , 1This ‚Ñ¶ ( Nc ) lower bound recently improved ‚Ñ¶ ( N2‚àío ( 1 ) ) G√∂√∂s Rubinstein [ 69 ] ( constant  > 0 N ‚Üí‚àû ) . proof follows high-level road map used ( see Section 2.5 ) , number additional optimizations . 2See also footnote 14 Solar Lecture 1 . 23 types protocols induced uncoupled dynamics ( see Section 1.2.4 ) . good news argument deterministic case already showcase conceptual ideas proof Theorem 2.1 . Extending proof randomized protocols requires substituting simulation theorem randomized protocols ( ‚Äô use simulation theorem deterministic protocols , see Theorem 2.7 ) minor tweaks.3 2.2 Naive Approach : Reduction Disjointness illustrate difficulty proving result like Theorem 2.1 , consider naive attempt tries reduce , say , Disjointness problem problem computing -NE , YES-instances mapped games equilibria property Œ† , NO-instances mapped games equilibrium property Œ† ( Figure 2.1 ) .4 reduction useful , Œ† needs property checked little communication , ‚Äú Alice plays first strategy positive probability ‚Äù ‚Äú Bob ‚Äô strategy full support. ‚Äù problem impossible ! reason problem computing approximate Nash equilibrium polylogarithmic nondeterministic communication complexity ( existence sparse approximate equilibria , see Theorem 1.15 Corollary 1.16 ) , Disjointness function ( 1-inputs ) . reduction proposed form would translate nondeterministic lower bound latter problem one former , hence exist.5 failed reduction highlights two different challenges . first resolve typechecking error encountered standard decision problem , might might witness ( like Disjointness , witness element intersection ) , total search problem always witness ( like computing approximate Nash equilibrium , guaranteed exist Nash ‚Äô theorem ) . second challenge figure prove strong lower bound deterministic randomized communication complexity computing approximate Nash equilibrium without inadvertently proving ( non-existent ) lower bound nondeterministic protocols . resolve second challenge , ‚Äô make use simulation theorems lift query complexity lower bounds communication complexity lower bounds ( see Section 2.7 ) ; tailored specific computational model , like deterministic randomized protocols . first challenge , need identify total search problemwith high communication complexity . , total search problems , analog 3SAT Disjointness ? correct answer turns fixed-point computation . 3When Babichenko Rubinstein [ 9 ] first proved result ( late 2016 ) , state-of-the-art simultaneous theorems randomized protocols much primitive deterministic protocols . forced Babichenko Rubinstein [ 9 ] use relatively weak simulation theorem randomized case ( G√∂√∂s et al . [ 70 ] ) , led number additional technical details proof . Amazingly , full-blown randomized simulation theorem published shortly thereafter [ 5 , 71 ] ! hand , extending argument deterministic protocols randomized protocols relatively straightforward . 4Recall theDisjointness function : Alice Bob input strings , b ‚àà { 0 , 1 } n , output function ‚Äú 0 ‚Äù coordinate ‚àà { 1 , 2 , . . . , n } ai = bi = 1 ‚Äú 1 ‚Äù otherwise . One first things learn communication complexity nondeterministic communication complexity Disjointness ( certifying 1-inputs ) n ( see e.g . [ 98 , 137 ] ) . course one famous useful results communication complexity function ‚Äô randomized communication complexity ( two-sided error ) ‚Ñ¶ ( n ) [ 88 , 128 ] . 5Mika G√∂√∂s ( personal communication , January 2018 ) points clever reductions Disjointness , starting Raz Wigderson [ 127 ] , imply strong lower bounds randomized communication complexity certain problems low nondeterministic communication complexity ; plausible Raz-Wigderson-style proof , search problems G√∂√∂s Pitassi [ 68 ] , could adapted give alternative proof Theorem 2.1 . 24 ‚Äú YES ‚Äù ‚Äú ‚Äù Disjointness Œµ-Nash Equilibria Every equilibrium satisfies œÄ equilibrium satisfies œÄ Figure 2.1 : naive attempt reduce theDisjointness problem problem computing approximate Nash equilibrium . 2.3 Finding Brouwer Fixed Points ( -BFP Problem ) section next describe reductions computing Nash equilibria computing fixed points , computing fixed points path-following problem . reductions classical . content proof Theorem 2.1 reductions opposite direction ; discussed Solar Lecture 3 . 2.3.1 Brouwer ‚Äô Fixed-Point Theorem Brouwer ‚Äô fixed-point theorem states whenever stir coffee , point ends exactly began . prefer formal statement : Theorem2.2 ( Brouwer ‚Äô Fixed-Point Theorem ( 1910 ) ) . IfC compact convex subset ofRd , f : C ‚Üí C continuous , exists fixed point : point x ‚àà C f ( x ) = x . hypotheses necessary.6 interested computational version Brouwer ‚Äô fixed-point theorem , -BFP problem : -BFP Problem ( Generic Version ) given description compact convex set C ‚äÜ Rd continuous function f : C ‚Üí C , output -approximate fixed point , meaning point x ‚àà C ‚Äñ f ( x ) ‚àí x‚Äñ <  . -BFP problem , many different forms , plays starring role study equilibrium computation . setC typically fixed advance , example d-dimensional hypercube . much work -BFP problem focused ` ‚àû norm ( e.g . [ 79 ] ) , one innovation proof Theorem 2.1 instead use normalized version ` 2 norm ( following Rubinstein [ 142 ] ) . Nailing problem precisely requires committing family succinctly described continuous functions f . description family used proof Theorem 2.1 technical best left 6If convexity dropped , consider rotating annulus centered origin . boundedness dropped , consider x 7‚Üí x + 1 R. closedness dropped , consider x 7‚Üí x2 ( 0 , 1 ] . continuity dropped , consider x 7‚Üí ( x + 12 ) mod 1 [ 0 , 1 ] . Many general fixed-point theorems known , find applications economics elsewhere ; see e.g . [ 15 , 108 ] . 25 Section 3.1 . Often ( lectures ) , family functions considered contains ( 1 ) -Lipschitz functions.7 particular , guarantees existence -approximate fixed point description length polynomial dimension log 1 ( rounding exact fixed point nearest neighbor suitably defined grid ) . 2.3.2 Brouwer Nash Fixed-point theorems long used prove equilibrium existence results , including original proofs Minimax theorem ( Theorem 1.1 ) Nash ‚Äô theorem ( Theorem 1.14 ) .8 Analogously , algorithms computing ( approximate ) fixed points used compute ( approximate ) Nash equilibria . Fact 2.3 . Existence/computation -NE reduces -BFP . provide details , let ‚Äô sketch Nash ‚Äô theorem ( Theorem 1.14 ) reduces Brouwer ‚Äô fixed- point theorem ( Theorem 2.2 ) , following version argument Geanakoplos [ 63 ] .9 Consider bimatrix game ( , B ) let S1 , S2 denote strategy sets Alice Bob ( i.e. , rows columns ) . relevant convex compact set C = ‚àÜ1 √ó ‚àÜ2 , ‚àÜi simplex representing mixed strategies Si . want define continuous function f : C ‚Üí C , mixed strategy profiles mixed strategy profiles , fixed points f Nash equilibria game . define f separately component fi : C ‚Üí ‚àÜi = 1 , 2 . natural idea set fi best response player mixed strategy player . lead continuous , even well defined , function . instead use ‚Äú regularized ‚Äù version idea , defining f1 ( x1 , x2 ) = argmax x‚Ä≤1‚àà‚àÜ1 g1 ( x ‚Ä≤1 , x2 ) , ( 2.1 ) g1 ( x ‚Ä≤1 , x2 ) = ( x ‚Ä≤1 ) > Ax2Ô∏∏ Ô∏∑Ô∏∑ Ô∏∏ linear x‚Ä≤1 ‚àí ‚Äñx ‚Ä≤1 ‚àí x1‚Äñ22Ô∏∏ Ô∏∑Ô∏∑ Ô∏∏ strictly convex , ( 2.2 ) similarly f2 g2 ( Bob ‚Äô payoff matrix B ) . first term function gi encourages best response second ‚Äú penalty term ‚Äù discourages big changes player ‚Äô mixed strategy . function gi strictly concave x ‚Ä≤i , fi well defined . function f = ( f1 , f2 ) continuous ( check ) . definition , every Nash equilibrium given game fixed point f . converse , suppose ( x1 , x2 ) Nash equilibrium , Alice ( say ) able increase expected payoff deviating unilaterally x1 x ‚Ä≤1 . simple computation shows , sufficiently small  > 0 , g1 ( ( 1 ‚àí  ) x1 +  x ‚Ä≤1 , x2 ) > g1 ( x1 , x2 ) , hence ( x1 , x2 ) fixed point f ( check ) . Summarizing , oracle computing Brouwer fixed point immediately gives oracle computing Nash equilibrium bimatrix game . argument applies games ( finite ) number players . argument also shows oracle computing -approximate fixed point ` ‚àû norm used compute (  ) -approximate Nash equilibrium game . first high-level goal 7Recall function f mapping metric space ( X , ) Œª-Lipschitz ( f ( x ) , f ( ) ) ‚â§ Œª ¬∑ ( x , ) x , ‚àà X . , function amplify distances points Œª factor . 8In fact , story behind von Neumann ‚Äô original proof Minimax theorem little complicated nuanced ; see Kjeldsen [ 94 ] fascinating detailed discussion . 9This discussion borrowed [ 136 , Lecture 20 ] . 26 witnesses canonical source Figure 2.2 : instance EoL problem corresponds directed graph in- out-degrees 1 . Solutions correspond sink vertices source vertices given one . proof Theorem 2.1 reverse direction reduction‚Äîto show problem computing approximate Nash equilibrium general computing approximate fixed point , rather merely special case . Goal # 1 -BFP ‚â§ -NE goal follows tradition sequence celebrated computational hardness results last decade computing exact Nash equilibrium ( -approximate Nash equilibrium  polynomial 1 n ) [ 46 , 34 ] . couple immediate issues . First , ‚Äô clear meaningfully define -BFP problem two-party communication model‚Äîwhat Alice ‚Äô Bob ‚Äô inputs ? ‚Äô address issue Section 3.1 . Second , even figure define -BFP problem implement goal # 1 , -NE problem least hard -BFP problem , makes us sure latter hard ? brings us next topic‚Äîa ‚Äú generic ‚Äù total search problem hard almost definition used transfer hardness problems ( like -BFP ) via reductions.10 2.4 End-of-the-Line ( EoL ) Problem 2.4.1 Problem Definition equilibrium fixed-point computation problems , turns appropriate ‚Äú generic ‚Äù problem involves following path large graph ; see also Figure 2.2 . EoL Problem ( Generic Version ) 10For analogy , ‚Äú generic ‚Äù hard decision problem complexity class NP : given description polynomial-time verifier , exist witness ( i.e. , input accepted verifier ) ? 27 Figure 2.3 : subdivided triangle plane . given description directed graph G maximum in- out-degree 1 , source vertex G , find either sink vertex G source vertex s. restriction in- out-degrees forces graph G consist vertex-disjoint paths cycles , least one path ( starting source ) . EoL problem total search problem‚Äîthere always solution , nothing else end path starts s. Thus instance EoL always solved rotely following path ; question whether clever algorithm always avoids searching entire graph . plausible EoL problem hard , sense algorithm always improves rote path-following ; see also Section 2.6 . -BFP problem ? lot , turns . Fact 2.4 . problem computing approximate Brouwer fixed point reduces EoL problem ( i.e. , -BFP ‚â§ EoL ) . 2.4.2 EoL Sperner ‚Äô Lemma basic reason fixed-point computation reduces path-following Sperner ‚Äô lemma , recall next ( borrowing [ 136 , Lecture 20 ] ) . Consider subdivided triangle plane ( Figure 2.3 ) . legal coloring vertices colors top corner vertex red , left corner vertex green , right corner vertex blue . vertex boundary must one two colors endpoints side . Internal vertices allowed possess three colors . small triangle trichromatic three colors represented vertices . Sperner ‚Äô lemma asserts every legal coloring , least one trichromatic triangle.11 Theorem 2.5 ( Sperner ‚Äô Lemma [ 147 ] ) . every legal coloring subdivided triangle , odd number trichromatic triangles . Proof . proof constructive . Define undirected graph G one vertex corresponding small triangle , plus source vertex corresponds region outside big triangle . graph G one edge pair small triangles share side one red one green endpoint . Every trichromatic small triangle corresponds degree-one vertex G. Every small triangle one green 11The result proof extend induction higher dimensions . Every subdivided simplex Rn vertices legally colored n + 1 colors odd number panchromatic subsimplices , different color vertex . 28 two red corners two green one red corners corresponds vertex degree two G. source vertex G degree equal number red-green segments left side big triangle , odd number . every undirected graph even number vertices odd degree , odd number trichromatic triangles .  proof Sperner ‚Äô lemma shows following path canonical source vertex suitable graph leads trichromatic triangle . Thus , computing trichromatic triangle legally colored subdivided triangle reduces EoL problem.12 2.4.3 Sperner Brouwer Next ‚Äô use Sperner ‚Äô lemma prove Brouwer ‚Äô fixed-point theorem 2-dimensional simplex ‚àÜ ; higher-dimensional versions Sperner ‚Äô lemma ( see footnote 11 ) similarly imply Brouwer ‚Äô fixed-point theorem simplices arbitrary dimension.13 Let f : ‚àÜ ‚Üí ‚àÜ Œª-Lipschitz function ( respect ` 2 norm , say ) . 1 . Subdivide ‚àÜ sub-triangles side length /Œª . Think points ‚àÜ parameterized three coordinates ( x , , z ) , x , , z ‚â• 0 x + + z = 1 . 2 . Associate three coordinates distinct color . color point ( x , , z ) , consider image ( x ‚Ä≤ , y‚Ä≤ , z‚Ä≤ ) f choose color coordinate strictly decreased ( none , ( x , , z ) fixed point ‚Äô done ) . Note conditions Sperner ‚Äô lemma satisfied . 3 . claim center ( x¬Ø , y¬Ø , z¬Ø ) trichromatic triangle must anO (  ) -fixed point ( ` ‚àû norm ) . corner triangle x-coordinate go f , ( x¬Ø , y¬Ø , z¬Ø ) distance /Œª corner , f Œª-Lipschitz , x-coordinate f ( x¬Ø , y¬Ø , z¬Ø ) x¬Ø +O (  ) . argument applies y¬Ø z¬Ø , implies coordinates f ( x¬Ø , y¬Ø , z¬Ø ) within ¬±O (  ) corresponding coordinate ( x¬Ø , y¬Ø , z¬Ø ) . Brouwer ‚Äô fixed-point theorem follows taking limit  ‚Üí 0 using continuity f . second high-level goal proof Theorem 2.1 reverse direction reduction -BFP EoL . , would like show problem computing approximate Brouwer fixed point general every path-following problem ( form EoL ) , rather merely special case . Goal # 2 EoL ‚â§ -BFP succeed implementing goals # 1 # 2 , also prove directly EoL problem hard , ‚Äô proven hardness problem computing approximate Nash equilibrium . 12We ‚Äô glossing details . graph instance EoL directed , graph G defined proof Theorem 2.5 undirected . , however , canonical way direct edges graph G. Also , canonical source vertex EoL instance out-degree 1 , source graph G degree 2k ‚àí 1 positive integer k. rectified splitting source vertex G k vertices , source vertex out-degree 1 k ‚àí 1 vertices in- out-degree 1 . 13Every compact convex subset finite-dimensional Euclidean space homeomorphic simplex dimension ( scaling radial projection , essentially ) , homeomorphisms preserve fixed points , Brouwer ‚Äô fixed-point theorem carries simplices compact convex subsets Euclidean space . 29 2.5 Road Map Proof Theorem 2.1 high-level plan proof rest next lecture show low-cost communication protocol -NE implies low-cost communication protocol -2BFP , -2BFP two-party version problem computing fixed point ( defined ) , implies low-cost communication protocol 2EoL , 2EoL two-party version EoL problem ( defined ) , implies low-query algorithm EoL . Finally , ‚Äô prove directly EoL problem admit low-query algorithm . gives us four things prove ( hardness EoL three implications ) ; ‚Äô tackle one one reverse order : Road Map Step 1 : Query lower bound EoL . Step 2 : Communication complexity lower bound 2EoL via simulation theorem . Step 3 : 2EoL reduces -2BFP . Step 4 : -2BFP reduces -NE . first step ( Section 2.6 ) easy . second step ( Section 2.7 ) follows directly one simulation theorems alluded Section 2.1 . last two steps , correspond goals # 2 # 1 , respectively , harder deferred Solar Lecture 3 . ingredients road map already present paper Roughgarden Wein- stein [ 140 ] , first paper define study two-party versions fixed-point computation problems , propose use simulation theorems context equilibrium computation . One major innovation Babichenko Rubinstein [ 9 ] use generic EoL problem base reduction , thereby eluding tricky interactions [ 140 ] simulation theorems ( seem inherently combinatorial ) fixed-point problems ( seem inherently geometric ) . Roughgarden Weinstein [ 140 ] applied simulation theorem directly fixed-point problem ( relying strong query complexity lower bounds finding fixed points [ 79 , 8 ] ) , yielded hard unwieldy version two-party fixed-point problem . clear reduce version problem computing approximate Nash equilibrium . Babichenko Rubinstein [ 9 ] instead apply simulation theorem directly EoL problem , results reasonably natural two-party version problem ( see Section 2.7 ) . significant flexibility interpret problem two-party fixed-point problem , interpretation Babichenko Rubinstein [ 9 ] ( see Section 3.1 ) yields version problem hard yet structured enough solved using approximate Nash equilibrium computation . second innovation [ 9 ] reduction -2BFP -NE ( see Section 3.2 ) , difficult , new clever.14 14Very recently , Ganor et al . [ 61 ] showed implement directly road map Roughgarden Weinstein [ 140 ] , thereby giving alternative proof Theorem 2.1 . 30 2.6 Step 1 : Query Lower Bound EoL consider following ‚Äú oracle ‚Äù version EoL problem . vertex set V fixed { 0 , 1 } n. Let N = |V | = 2n . Algorithms allowed access graph vertex queries . query vertex v reveals alleged predecessor pred ( v ) ( , otherwise pred ( v ) NULL ) alleged successor succ ( v ) ( NULL successor ) . interpretation directed edge ( v , w ) belongs implicitly defined directed graph G = ( V , E ) succ ( v ) = w pred ( w ) = v. semantics guarantee graph in- out-degree 1.15 also assume pred ( 0n ) = NULL , interpret vertex 0n priori known source vertex graph . version EoL problem oracle model : EoL Problem ( Query Version ) given oracle , find vertex v ‚àà V satisfies one following : ( ) succ ( v ) NULL ; ( ii ) pred ( v ) NULL v , 0n ; ( iii ) v , pred ( succ ( v ) ) ; ( iv ) v , succ ( pred ( v ) ) v , 0n . According semantics , cases ( iii ) ( iv ) imply v sink source vertex , respectively . solution guaranteed exist‚Äîif nothing else , end path G originates vertex 0n . sometimes convenient restrict ‚Äú promise ‚Äù version EoL problem ( easier ) , graph G guaranteed single Hamiltonian path . Even special case , every vertex query reveals information three vertices , following . Proposition 2.6 ( Query Lower Bound EoL ) . Every deterministic algorithm solves EoL problem requires ‚Ñ¶ ( N ) queries worst case , even instances consist single Hamiltonian path . Slightly formally , consider adversary always responds values succ ( v ) pred ( v ) never-before-seen vertices ( except necessary maintain consistency adversary ‚Äô answers , cases ( iii ) ( iv ) never occur ) . ( N ) queries , known parts G constitute bunch vertex-disjoint paths , G could Hamiltonian path V consistent . end Hamiltonian path could ‚Ñ¶ ( N ) different vertices , algorithm way knowing one.16 15For proof Theorem 2.1 , could restrict attention instances consistent sense succ ( v ) = w pred ( w ) = v. computational hardness results Solar Lectures 4 5 require general ( non-promise ) version problem stated . 16A similar argument , based choosing Hamiltonian path V random , implies ‚Ñ¶ ( N ) lower bound randomized query complexity well . 31 2.7 Step 2 : Communication Complexity Lower Bound 2EoL via Simu- lation Theorem next step use ‚Äú simulation theorem ‚Äù transfer query lower bound EoL problem communication lower bound two-party version problem , 2EoL.17 exact definition 2EoL problem determined output simulation theorem . 2.7.1 Query Model Consider arbitrary function f : Œ£N ‚Üí Œ£ , Œ£ denotes finite alphabet . input z = ( z1 , . . . , zN ) ‚àà Œ£N , initially unknown algorithm . algorithm query input z adaptively , query revealing zi coordinate algorithm ‚Äô choosing . trivial evaluate f ( z ) using N queries ; question whether algorithm always better ( function f interest ) . example , query version EoL problem Proposition 2.6 viewed special case model , Œ£ =